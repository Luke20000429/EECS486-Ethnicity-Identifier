{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd08d7437d109cb4990f43ee27100ea9916bfedca7758194b0fcdd55f6030d2bfdf",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import random\n",
    "\n",
    "from ngram import getNgrams, getGrams, getFix\n",
    "from dataHandler import readData as rd\n",
    "from combMethod import EthnicityPredictor as EP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer(EP):\n",
    "\n",
    "    def analyze(self):\n",
    "\n",
    "        self.readData()\n",
    "        print(\"Finish reading!\\n\")\n",
    "        # self.countNN()\n",
    "        self.countCate()\n",
    "        print(\"ready!\\n\")\n",
    "\n",
    "    def sortGram(self, N, region):\n",
    "        sortgram = sorted(self.ngrams[N-1][region].items(), key = lambda kv:(kv[1], kv[0]), reverse=True)\n",
    "        return sortgram\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Finish reading!\n",
      "\n",
      "ready!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "anlz = Analyzer(3)\n",
    "anlz.analyze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "get pre/suffix\n"
     ]
    }
   ],
   "source": [
    "prefix = getFix(2, anlz.pairs, anlz.nations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"unigram.csv\", 'w', encoding=\"utf-8\") as f:\n",
    "    for rid in range(len(anlz.nations)):\n",
    "        line = \"%s\"%anlz.nations[rid][0]\n",
    "        for gram,count in anlz.sortGram(1, rid):\n",
    "            line += \",%s %d\"%(gram, count)\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"bigram.csv\", 'w', encoding=\"utf-8\") as f:\n",
    "    for rid in range(len(anlz.nations)):\n",
    "        line = \"%s\"%anlz.nations[rid][0]\n",
    "        for gram,count in anlz.sortGram(2, rid):\n",
    "            line += \",%s %d\"%(gram, count)\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"trigram.csv\", 'w', encoding=\"utf-8\") as f:\n",
    "    for rid in range(len(anlz.nations)):\n",
    "        line = \"%s\"%anlz.nations[rid][0]\n",
    "        for gram,count in anlz.sortGram(3, rid):\n",
    "            line += \",%s %d\"%(gram, count)\n",
    "        f.write(line+'\\n')"
   ]
  }
 ]
}