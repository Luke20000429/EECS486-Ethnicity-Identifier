{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python386jvsc74a57bd08d7437d109cb4990f43ee27100ea9916bfedca7758194b0fcdd55f6030d2bfdf",
   "display_name": "Python 3.8.6 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "source": [
    "Merge data from each dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read archive data\n",
    "src = open(\"./archive/nana/train.src\", 'r', encoding='utf-8')\n",
    "tgt = open(\"./archive/nana/train.tgt\", 'r', encoding='utf-8')\n",
    "nations = dict()\n",
    "count = np.zeros(1000)\n",
    "num_nation = 0\n",
    "info = []\n",
    "name_list = []\n",
    "for l1, l2 in zip(src, tgt):\n",
    "    names = l1[:-1].lower().replace(\",\", \"\").split(\" \")\n",
    "    nation = l2[:-1].lower()\n",
    "    if nation not in nations.keys():\n",
    "        nations[nation] = num_nation\n",
    "        num_nation += 1 \n",
    "    for name in names:\n",
    "        info.append((name, nations[nation]))\n",
    "    count[nations[nation]] += 1\n",
    "\n",
    "src.close()\n",
    "tgt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read nationality-classify data\n",
    "file_list = os.listdir(\"./archive/datasets\")\n",
    "for fname in file_list:\n",
    "    nation = fname.replace(\".txt\", \"\")\n",
    "    if nation not in nations.keys():\n",
    "        nations[nation] = num_nation\n",
    "        num_nation += 1\n",
    "    count[nations[nation]] += 1\n",
    "    with open(os.path.join(\"./archive/datasets\", fname), 'r', encoding='utf-8') as f:\n",
    "        for l in f:\n",
    "            names = l1[:-1].lower().split(\" \")\n",
    "            info.append((name, nations[nation]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## translate nation to region\n",
    "## na2re[nation_id] -> rid\n",
    "na2re = []\n",
    "regions = dict()\n",
    "with open(\"./archive/nation-region.txt\", 'r', encoding='utf-8') as f:\n",
    "    num = 0\n",
    "    for line in f:\n",
    "        region = line[:-1].split(',')[1]\n",
    "        if region not in regions.keys():\n",
    "            regions[region] = num\n",
    "            num += 1\n",
    "        na2re.append(regions[region])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read and write test dataset\n",
    "src = open(\"./archive/nana/test.src\", 'r', encoding='utf-8')\n",
    "tgt = open(\"./archive/nana/test.tgt\", 'r', encoding='utf-8')\n",
    "test_set = open(\"test_set.txt\", 'w', encoding='utf-8')\n",
    "\n",
    "for l1, l2 in zip(src, tgt):\n",
    "    names = l1[:-1].lower().replace(\",\", \"\")\n",
    "    nation = l2[:-1].lower()\n",
    "    test_set.write(\"%s #%d\\n\"%(names, na2re[nations[nation]]))\n",
    "\n",
    "test_set.close()\n",
    "src.close()\n",
    "tgt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write name : nation data\n",
    "sort_nations = sorted(nations.keys())\n",
    "# info_set = set(info)\n",
    "info_set = info\n",
    "data = open(\"./data/db.txt\", 'w', encoding='utf-8')\n",
    "for name, nid in info_set:\n",
    "    if len(name) >= 3 and name.isalpha():\n",
    "        data.write(\"%s %d\\n\"%(name, nid))\n",
    "\n",
    "with open(\"./data/nations.txt\", 'w', encoding='utf-8') as f:\n",
    "    for nation in nations.keys():\n",
    "        f.write(\"%s\\n\"%(nation))\n",
    "\n",
    "data.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read all names\n",
    "names = []\n",
    "with open(\"./data/db.txt\", 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        name = line[:-1].split(\",\")[0]\n",
    "        names.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## translate (name : nation_id) to (name : region_id)\n",
    "db = open(\"./data/db.txt\", 'r', encoding='utf-8')\n",
    "redb = open(\"./data/redb.txt\", 'w', encoding='utf-8')\n",
    "\n",
    "recount = np.zeros(13)\n",
    "\n",
    "for line in db:\n",
    "    name, nation = line[:-1].split(\" \")\n",
    "    if name != \"mccaughey\": \n",
    "        ## error name in the data set\n",
    "        re = na2re[int(nation)]\n",
    "        recount[re] += 1\n",
    "        redb.write(\"%s %d\\n\"%(name, re))\n",
    "\n",
    "db.close()\n",
    "redb.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n"
     ]
    }
   ],
   "source": [
    "## write region : region_id\n",
    "with open(\"./data/regions.txt\", 'w', encoding='utf-8') as f:\n",
    "    for region, rid in regions.items():\n",
    "        print(rid)\n",
    "        f.write(\"%s %d\\n\"%(region, recount[rid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}